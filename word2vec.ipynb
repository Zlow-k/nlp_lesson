{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import MeCab\n",
    "import ipadic\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"sample_data/*.txt\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list = []\n",
    "\n",
    "m = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
    "pattern = re.compile(r\"[ぁ-んァ-ヶ一-龥々]\")\n",
    "\n",
    "for document in documents:\n",
    "    m1 = m.parse(document)\n",
    "    \n",
    "    noun_list =[]\n",
    "    for row in m1.split(\"\\n\"):\n",
    "        target_word = row.split(\"\\t\")[0]\n",
    "        if target_word == \"EOS\":\n",
    "            break\n",
    "        else:\n",
    "            word = row.split(\"\\t\")[1]\n",
    "            if word[:2] == \"名詞\":\n",
    "                if pattern.findall(target_word) != []:\n",
    "                   noun_list.append(target_word)\n",
    "\n",
    "    document_list.append(noun_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(document_list, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0122616 ,  0.00902179, -0.00739908,  0.00771432,  0.00743133,\n",
       "       -0.01100327,  0.0151678 ,  0.01973677, -0.01873679,  0.00405009,\n",
       "       -0.01087725, -0.0070978 ,  0.00665885,  0.00520668, -0.00376845,\n",
       "       -0.01107796,  0.0094733 , -0.01690548,  0.00153376, -0.0270005 ,\n",
       "        0.01946209, -0.00364027,  0.0158239 , -0.00823853, -0.01379371,\n",
       "       -0.00675557, -0.01022481,  0.00025226, -0.00881321,  0.00926076,\n",
       "        0.01527397,  0.00195351,  0.00426688, -0.00036546, -0.0050757 ,\n",
       "        0.01501064, -0.00838694, -0.00337826, -0.00519734, -0.01754157,\n",
       "        0.00850792, -0.01098611, -0.0075116 ,  0.00066553,  0.00675245,\n",
       "       -0.00836985, -0.00292619, -0.00912278,  0.01180797,  0.00661159,\n",
       "        0.00918254, -0.00321193, -0.00367542,  0.00013294, -0.00954761,\n",
       "        0.00933538,  0.01032533, -0.00372684, -0.02075512, -0.008158  ,\n",
       "        0.00435496, -0.00246984, -0.00639153, -0.00342694, -0.02136916,\n",
       "        0.01281041,  0.00799696,  0.003867  , -0.02142112,  0.01555824,\n",
       "       -0.00700689, -0.00091795,  0.00939226, -0.00441424,  0.00840803,\n",
       "       -0.00703437,  0.0064226 ,  0.00199201, -0.00992616,  0.01242063,\n",
       "       -0.00857664,  0.00372303, -0.00914123,  0.02049029, -0.00073182,\n",
       "       -0.00660573, -0.00367729,  0.02084877,  0.01204981,  0.00367743,\n",
       "        0.01998939, -0.001477  ,  0.00138448, -0.00451901,  0.01011057,\n",
       "       -0.0013779 ,  0.00935059, -0.00585821,  0.0082626 ,  0.0025421 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"放送\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec_a, vec_b):\n",
    "    dot = np.dot(vec_a, vec_b)\n",
    "    norm_a = np.linalg.norm(vec_a)\n",
    "    norm_b = np.linalg.norm(vec_b)\n",
    "    return dot / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54848087"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(model.wv[\"放送\"], model.wv[\"視聴\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('の', 0.7041606903076172),\n",
       " ('日本', 0.6735050082206726),\n",
       " ('こと', 0.6624571681022644),\n",
       " ('ため', 0.6587678790092468),\n",
       " ('ん', 0.6579837203025818)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"視聴\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
