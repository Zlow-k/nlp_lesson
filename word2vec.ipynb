{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import MeCab\n",
    "import ipadic\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"sample_data/*.txt\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file_path in files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list = []\n",
    "\n",
    "m = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
    "pattern = re.compile(r\"[ぁ-んァ-ヶ一-龥々]\")\n",
    "\n",
    "for document in documents:\n",
    "    m1 = m.parse(document)\n",
    "    \n",
    "    noun_list =[]\n",
    "    for row in m1.split(\"\\n\"):\n",
    "        target_word = row.split(\"\\t\")[0]\n",
    "        if target_word == \"EOS\":\n",
    "            break\n",
    "        else:\n",
    "            word = row.split(\"\\t\")[1]\n",
    "            if word[:2] == \"名詞\":\n",
    "                if pattern.findall(target_word) != []:\n",
    "                   noun_list.append(target_word)\n",
    "\n",
    "    document_list.append(noun_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(document_list, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01223801,  0.00899587, -0.00742968,  0.00768361,  0.00733178,\n",
       "       -0.0109793 ,  0.01513781,  0.01975149, -0.0187292 ,  0.00405822,\n",
       "       -0.01087262, -0.00713097,  0.0066231 ,  0.0051896 , -0.00376334,\n",
       "       -0.01117102,  0.00956615, -0.01695116,  0.00156113, -0.0269539 ,\n",
       "        0.01944072, -0.00366285,  0.01575053, -0.00824062, -0.01383275,\n",
       "       -0.00673301, -0.01022001,  0.00027153, -0.00880882,  0.00927916,\n",
       "        0.01530651,  0.00194911,  0.00422172, -0.00035427, -0.00509598,\n",
       "        0.01499727, -0.00834502, -0.00342295, -0.00518718, -0.0175535 ,\n",
       "        0.00845263, -0.01097074, -0.00749972,  0.00063815,  0.00681255,\n",
       "       -0.00838283, -0.00290042, -0.00911621,  0.0117795 ,  0.00662136,\n",
       "        0.00911904, -0.00320179, -0.00363818,  0.00017367, -0.00949273,\n",
       "        0.00931522,  0.01036452, -0.00371016, -0.02073824, -0.00818164,\n",
       "        0.00437739, -0.00243505, -0.00645005, -0.00339031, -0.02134898,\n",
       "        0.01282998,  0.00800594,  0.00387142, -0.02135232,  0.01553747,\n",
       "       -0.00696574, -0.00092905,  0.00934109, -0.00445063,  0.00843167,\n",
       "       -0.00704832,  0.00639205,  0.0020369 , -0.00988577,  0.01246412,\n",
       "       -0.00855012,  0.0036535 , -0.00914267,  0.02054117, -0.00066449,\n",
       "       -0.0066178 , -0.00364363,  0.02085129,  0.01203685,  0.00368923,\n",
       "        0.01999083, -0.00150852,  0.00136228, -0.00452195,  0.01006845,\n",
       "       -0.00140616,  0.0093449 , -0.00591436,  0.00824333,  0.00257846],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"放送\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vec_a, vec_b):\n",
    "    dot = np.dot(vec_a, vec_b)\n",
    "    norm_a = np.linalg.norm(vec_a)\n",
    "    norm_b = np.linalg.norm(vec_b)\n",
    "    return dot / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54794896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(model.wv[\"放送\"], model.wv[\"視聴\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('の', 0.703569233417511),\n",
       " ('日本', 0.6732020974159241),\n",
       " ('こと', 0.6616107225418091),\n",
       " ('ため', 0.65836101770401),\n",
       " ('ん', 0.6570427417755127)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"視聴\", topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ストップワードを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open(\"stop_words.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for row in f.readlines():\n",
    "        stop_words.append(row.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_list = []\n",
    "\n",
    "m = MeCab.Tagger(ipadic.MECAB_ARGS)\n",
    "pattern = re.compile(r\"[ぁ-んァ-ヶ一-龥々]\")\n",
    "\n",
    "for document in documents:\n",
    "    m1 = m.parse(document)\n",
    "    \n",
    "    noun_list =[]\n",
    "    for row in m1.split(\"\\n\"):\n",
    "        target_word = row.split(\"\\t\")[0]\n",
    "        if target_word == \"EOS\":\n",
    "            break\n",
    "        else:\n",
    "            word = row.split(\"\\t\")[1]\n",
    "            if word[:2] == \"名詞\":\n",
    "                if pattern.findall(target_word) != [] and target_word not in stop_words:\n",
    "                   noun_list.append(target_word)\n",
    "\n",
    "    document_list.append(noun_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(document_list, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27328742"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(model.wv[\"放送\"], model.wv[\"視聴\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('記事', 0.49594712257385254),\n",
       " ('話題', 0.49297645688056946),\n",
       " ('番組', 0.48523572087287903),\n",
       " ('ネット', 0.4701656103134155),\n",
       " ('批判', 0.45258843898773193)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"視聴\", topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文章の類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"私\", \"は\", \"報道\", \"アナウンサー\", \"です\"]\n",
    "\n",
    "word_vec = []\n",
    "\n",
    "for word in sentence:\n",
    "    if word in model.wv:\n",
    "        word_vec.append(model.wv[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00250608,  0.00617311, -0.00019012,  0.01070487,  0.00344567,\n",
       "        -0.00387439,  0.00242922,  0.01281414,  0.0019681 , -0.00227902,\n",
       "         0.00147246, -0.01029242,  0.00373494,  0.00741207,  0.00418108,\n",
       "        -0.00866058, -0.00465111, -0.00234443, -0.00560736, -0.01059185,\n",
       "         0.00306205,  0.00746861, -0.00432432,  0.0074281 , -0.00310169,\n",
       "        -0.00461752, -0.00097507, -0.00542675, -0.01225483, -0.00456709,\n",
       "         0.00529901, -0.00666004,  0.00168128, -0.00074992, -0.0051614 ,\n",
       "         0.00753335,  0.00361974,  0.00594313, -0.00202876, -0.00848688,\n",
       "         0.00376762, -0.00562216, -0.01415814,  0.00955153,  0.00207945,\n",
       "        -0.01175285, -0.01211939, -0.00452767,  0.00493611,  0.00865615,\n",
       "         0.00829657, -0.01244357, -0.00217279, -0.00393765, -0.00883374,\n",
       "         0.01009202,  0.00680818, -0.00452568, -0.01388145, -0.00408897,\n",
       "         0.00031419,  0.00930025,  0.00415155, -0.00817937, -0.01619464,\n",
       "         0.01157124, -0.00071848,  0.00059852, -0.0004223 , -0.00037317,\n",
       "         0.00180768,  0.0029188 , -0.00200585, -0.00477894,  0.01065322,\n",
       "         0.01213726,  0.00197492,  0.00400626, -0.00955379,  0.00191823,\n",
       "        -0.00773021,  0.00114635, -0.00435549,  0.00344346, -0.00752852,\n",
       "         0.01104525,  0.00463837,  0.00217352,  0.00252393,  0.01056719,\n",
       "        -0.00314349,  0.00575045,  0.00093953,  0.0095557 ,  0.01586422,\n",
       "         0.00242266,  0.00474296, -0.00738986, -0.0084331 , -0.00100844],\n",
       "       dtype=float32),\n",
       " array([ 2.8003042e-03,  7.7256729e-04, -9.8069981e-03, -5.5954824e-03,\n",
       "        -4.5760488e-03, -8.2564689e-03,  5.7662390e-03,  4.2952425e-04,\n",
       "         5.2780919e-03,  8.3823670e-03, -6.2162761e-04,  8.3378274e-03,\n",
       "         2.6905572e-03, -9.0106595e-03, -4.6476032e-04,  6.5052733e-03,\n",
       "        -9.7431578e-03, -4.0059984e-03, -7.3143388e-03,  8.0478197e-04,\n",
       "        -4.5321854e-03,  4.2664385e-03,  4.2337435e-03, -7.9171108e-03,\n",
       "        -3.0519620e-03, -2.9984689e-03, -5.6238874e-04, -3.5607135e-03,\n",
       "         8.2031237e-03, -1.6634464e-03,  5.5326810e-03, -7.3435507e-03,\n",
       "         9.0895686e-03, -1.1881950e-03,  1.2909932e-04,  8.7942332e-03,\n",
       "        -5.5526165e-05, -6.6561361e-06,  9.4774291e-03,  2.7847036e-03,\n",
       "         3.8047498e-03,  8.5233264e-03, -3.7804383e-03,  4.7455779e-03,\n",
       "         2.9259213e-04, -9.8888786e-04, -9.7864168e-03, -3.0612585e-03,\n",
       "        -1.7048102e-03,  9.3505997e-03,  4.2564245e-03,  7.0703221e-03,\n",
       "        -2.8897058e-03,  3.0984529e-03, -2.6702676e-03,  9.3476139e-03,\n",
       "        -5.2898349e-03, -3.4215758e-03,  5.2115596e-03,  5.0193151e-03,\n",
       "        -2.9715355e-03, -9.4549200e-03,  6.3482933e-03,  4.3038423e-03,\n",
       "        -8.7168664e-03, -3.7688930e-03, -2.6063118e-03, -3.3825445e-03,\n",
       "         7.4229562e-03,  5.7995846e-03, -6.1237616e-03,  3.5144952e-03,\n",
       "         4.9752439e-03,  4.1087172e-03,  8.4902076e-03,  4.3740366e-03,\n",
       "        -6.8662106e-03, -6.2903361e-03, -1.0088328e-02,  6.1728181e-03,\n",
       "        -2.3875532e-03,  7.2034788e-03, -1.0043098e-02, -8.5749254e-03,\n",
       "         8.5750418e-03, -9.6714720e-03, -3.8831113e-03,  6.5677320e-03,\n",
       "        -3.0041849e-03,  8.0845235e-03, -5.2025565e-03,  2.0385140e-03,\n",
       "        -2.6289234e-03,  3.4722881e-03,  8.4407320e-03,  1.0192107e-02,\n",
       "        -1.1549055e-04,  5.7663247e-03,  1.8990642e-03, -8.1701139e-03],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(word_vec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5070109e-05,  3.2929011e-04], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(word_vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_vec(sentence, model):\n",
    "    word_vec = [model.wv[word]for word in sentence if word in model.wv]\n",
    "    sentence_vec = np.mean(word_vec, axis=0)\n",
    "    \n",
    "    return sentence_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = cal_vec(document_list[38], model)\n",
    "vec2 = cal_vec(document_list[40], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91900086"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
